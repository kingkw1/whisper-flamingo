{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After submitting all jobs with `source slurm/whisper_decode_video_slurm_wrapper.sh`, use this notebook to print the results of all decoding runs. It will load the decoding WER / BLEU scores and print them in a convinient table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "def print_results(results, beam):\n",
    "    # Print table headers\n",
    "    print(\"Beam size: {}\".format(beam))\n",
    "    # Extract languages\n",
    "    languages = list(results[beam].keys())\n",
    "    # Extract results\n",
    "    audio_clean = [results[beam][lang][modalities[0]][str(noises[0])] for lang in languages]\n",
    "    audio_visual_clean = [results[beam][lang][modalities[1]][str(noises[0])] for lang in languages]\n",
    "    audio_babble_lrs3 = [results[beam][lang][modalities[0]][str(noises[1])] for lang in languages]\n",
    "    audio_visual_babble_lrs3 = [results[beam][lang][modalities[1]][str(noises[1])] for lang in languages]\n",
    "    # Print Audio-Clean row\n",
    "    print('Audio-Clean ', end='')\n",
    "    for val in audio_clean:\n",
    "        print(str(val) + ' ', end='')\n",
    "    print()\n",
    "    # Print Audio-Visual-Clean row\n",
    "    print('Audio-Visual-Clean ', end='')\n",
    "    for val in audio_visual_clean:\n",
    "        print(str(val) + ' ', end='')\n",
    "    print()\n",
    "    # Print Audio-Babble row\n",
    "    print('Audio-Babble-LRS3 ', end='')\n",
    "    for val in audio_babble_lrs3:\n",
    "        print(str(val) + ' ', end='')\n",
    "    print()\n",
    "    # Print Audio-Visual-Babble row\n",
    "    print('Audio-Visual-Babble-LRS3 ', end='')\n",
    "    for val in audio_visual_babble_lrs3:\n",
    "        print(str(val) + ' ', end='')\n",
    "    print()\n",
    "    print(\"Avg clean non En: {}\".format(round(sum(audio_clean[1:]) / (len(languages) -1), 1)))\n",
    "    print(\"Avg clean non En: {}\".format(round(sum(audio_visual_clean[1:]) / (len(languages) -1), 1)))\n",
    "    print(\"Avg noisy non En: {}\".format(round(sum(audio_babble_lrs3[1:]) / (len(languages) -1), 1)))\n",
    "    print(\"Avg noisy non En: {}\".format(round(sum(audio_visual_babble_lrs3[1:]) / (len(languages) -1), 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Languages en es fr it pt \n",
      "Beam size: 5\n",
      "Audio-Clean 0 0 0 0 0 \n",
      "Audio-Visual-Clean 4.21 9.56 13.77 12.74 12.87 \n",
      "Audio-Babble-LRS3 0 0 0 0 0 \n",
      "Audio-Visual-Babble-LRS3 8.73 33.61 31.94 41.19 42.78 \n",
      "Avg clean non En: 0.0\n",
      "Avg clean non En: 12.2\n",
      "Avg noisy non En: 0.0\n",
      "Avg noisy non En: 37.4\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# root = '../decode/models/checkpoint/'\n",
    "\n",
    "root = '../decode/models/'\n",
    "checkpoint = 'whisper-flamingo_multi-all_small.pt'\n",
    "\n",
    "# ASR zero-shot\n",
    "# root = '../decode/'\n",
    "# checkpoint = 'large-v2'\n",
    "# checkpoint = 'medium'\n",
    "# checkpoint = 'small'\n",
    "\n",
    "# fixed\n",
    "# langs = ['en', 'ar', 'de', 'el', 'es', 'fr', 'it', 'pt', 'ru'] \n",
    "langs = ['en', 'es', 'fr', 'it', 'pt',] \n",
    "# langs = ['en', 'ar', 'de', 'el', 'ru'] \n",
    "\n",
    "noises = [1000, 0] # clean, 0\n",
    "modalities = ['asr', 'avsr']\n",
    "# beams = [1]\n",
    "beams = [5]\n",
    "visible = 0 # full eval set\n",
    "noise_fn = 'lrs3'\n",
    "\n",
    "results = {beam: {lang: {modality: {str(noise): 0 for noise in noises} for modality in modalities} for lang in langs} for beam in beams}\n",
    "for beam in beams:\n",
    "    for lang in langs:\n",
    "        for noise in noises:\n",
    "            for modality in modalities:\n",
    "                try:\n",
    "                    # file = 'bleu.368862'\n",
    "                    file = 'wer.368862'\n",
    "                    with open(os.path.join(root, checkpoint, lang, 'test', modality, 'snr-{}'.format(noise), 'visible-{}'.format(visible), 'beam-{}'.format(beam), noise_fn, file)) as f:                    \n",
    "                        first_line = f.readline().strip('\\n')\n",
    "                        # prefix = 5 if lang == 'en' else 6\n",
    "                        prefix = 5\n",
    "                        results[beam][lang][modality][str(noise)] = round(float(first_line[prefix:]), 2)\n",
    "                except:\n",
    "                    continue\n",
    "    \n",
    "print('Languages ', end='')\n",
    "for lang in langs:\n",
    "    print(lang + ' ', end='')\n",
    "print()\n",
    "for beam in beams:\n",
    "    print_results(results, beam)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Noise Type Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lrs3\n",
      "muavic\n",
      "babble\n",
      "speech\n",
      "music\n",
      "noise\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'lrs3': {5: {'en': {'asr': {'-10': 0, '-5': 0, '0': 0, '5': 0, '10': 0},\n",
       "    'avsr': {'-10': 40.0, '-5': 25.7, '0': 7.5, '5': 3.8, '10': 3.4}},\n",
       "   'es': {'asr': {'-10': 0, '-5': 0, '0': 0, '5': 0, '10': 0},\n",
       "    'avsr': {'-10': 91.2, '-5': 70.3, '0': 28.0, '5': 13.9, '10': 9.9}},\n",
       "   'fr': {'asr': {'-10': 0, '-5': 0, '0': 0, '5': 0, '10': 0},\n",
       "    'avsr': {'-10': 98.1, '-5': 63.3, '0': 27.5, '5': 16.0, '10': 12.7}},\n",
       "   'it': {'asr': {'-10': 0, '-5': 0, '0': 0, '5': 0, '10': 0},\n",
       "    'avsr': {'-10': 92.7, '-5': 73.3, '0': 35.2, '5': 18.0, '10': 12.6}},\n",
       "   'pt': {'asr': {'-10': 0, '-5': 0, '0': 0, '5': 0, '10': 0},\n",
       "    'avsr': {'-10': 94.5, '-5': 74.3, '0': 36.0, '5': 20.0, '10': 13.7}}}},\n",
       " 'muavic': {5: {'en': {'asr': {'-10': 0, '-5': 0, '0': 0, '5': 0, '10': 0},\n",
       "    'avsr': {'-10': 40.9, '-5': 32.2, '0': 8.7, '5': 4.0, '10': 3.6}},\n",
       "   'es': {'asr': {'-10': 0, '-5': 0, '0': 0, '5': 0, '10': 0},\n",
       "    'avsr': {'-10': 97.6, '-5': 77.8, '0': 32.2, '5': 14.4, '10': 10.1}},\n",
       "   'fr': {'asr': {'-10': 0, '-5': 0, '0': 0, '5': 0, '10': 0},\n",
       "    'avsr': {'-10': 107.2, '-5': 75.1, '0': 30.7, '5': 17.1, '10': 12.7}},\n",
       "   'it': {'asr': {'-10': 0, '-5': 0, '0': 0, '5': 0, '10': 0},\n",
       "    'avsr': {'-10': 0, '-5': 0, '0': 37.0, '5': 18.3, '10': 12.6}},\n",
       "   'pt': {'asr': {'-10': 0, '-5': 0, '0': 0, '5': 0, '10': 0},\n",
       "    'avsr': {'-10': 100.4, '-5': 79.7, '0': 38.6, '5': 20.1, '10': 14.1}}}},\n",
       " 'babble': {5: {'en': {'asr': {'-10': 0, '-5': 0, '0': 0, '5': 0, '10': 0},\n",
       "    'avsr': {'-10': 39.7, '-5': 22.1, '0': 6.1, '5': 3.7, '10': 3.6}},\n",
       "   'es': {'asr': {'-10': 0, '-5': 0, '0': 0, '5': 0, '10': 0},\n",
       "    'avsr': {'-10': 91.0, '-5': 0, '0': 26.2, '5': 0, '10': 0}},\n",
       "   'fr': {'asr': {'-10': 0, '-5': 0, '0': 0, '5': 0, '10': 0},\n",
       "    'avsr': {'-10': 0, '-5': 0, '0': 0, '5': 0, '10': 0}},\n",
       "   'it': {'asr': {'-10': 0, '-5': 0, '0': 0, '5': 0, '10': 0},\n",
       "    'avsr': {'-10': 0, '-5': 0, '0': 0, '5': 0, '10': 0}},\n",
       "   'pt': {'asr': {'-10': 0, '-5': 0, '0': 0, '5': 0, '10': 0},\n",
       "    'avsr': {'-10': 0, '-5': 0, '0': 0, '5': 0, '10': 0}}}},\n",
       " 'speech': {5: {'en': {'asr': {'-10': 0, '-5': 0, '0': 0, '5': 0, '10': 0},\n",
       "    'avsr': {'-10': 0, '-5': 0, '0': 0, '5': 0, '10': 0}},\n",
       "   'es': {'asr': {'-10': 0, '-5': 0, '0': 0, '5': 0, '10': 0},\n",
       "    'avsr': {'-10': 0, '-5': 0, '0': 0, '5': 0, '10': 0}},\n",
       "   'fr': {'asr': {'-10': 0, '-5': 0, '0': 0, '5': 0, '10': 0},\n",
       "    'avsr': {'-10': 0, '-5': 0, '0': 0, '5': 0, '10': 0}},\n",
       "   'it': {'asr': {'-10': 0, '-5': 0, '0': 0, '5': 0, '10': 0},\n",
       "    'avsr': {'-10': 0, '-5': 0, '0': 0, '5': 0, '10': 0}},\n",
       "   'pt': {'asr': {'-10': 0, '-5': 0, '0': 0, '5': 0, '10': 0},\n",
       "    'avsr': {'-10': 0, '-5': 0, '0': 0, '5': 0, '10': 0}}}},\n",
       " 'music': {5: {'en': {'asr': {'-10': 0, '-5': 0, '0': 0, '5': 0, '10': 0},\n",
       "    'avsr': {'-10': 0, '-5': 0, '0': 0, '5': 0, '10': 0}},\n",
       "   'es': {'asr': {'-10': 0, '-5': 0, '0': 0, '5': 0, '10': 0},\n",
       "    'avsr': {'-10': 0, '-5': 0, '0': 0, '5': 0, '10': 0}},\n",
       "   'fr': {'asr': {'-10': 0, '-5': 0, '0': 0, '5': 0, '10': 0},\n",
       "    'avsr': {'-10': 0, '-5': 0, '0': 0, '5': 0, '10': 0}},\n",
       "   'it': {'asr': {'-10': 0, '-5': 0, '0': 0, '5': 0, '10': 0},\n",
       "    'avsr': {'-10': 0, '-5': 0, '0': 0, '5': 0, '10': 0}},\n",
       "   'pt': {'asr': {'-10': 0, '-5': 0, '0': 0, '5': 0, '10': 0},\n",
       "    'avsr': {'-10': 0, '-5': 0, '0': 0, '5': 0, '10': 0}}}},\n",
       " 'noise': {5: {'en': {'asr': {'-10': 0, '-5': 0, '0': 0, '5': 0, '10': 0},\n",
       "    'avsr': {'-10': 0, '-5': 0, '0': 0, '5': 0, '10': 0}},\n",
       "   'es': {'asr': {'-10': 0, '-5': 0, '0': 0, '5': 0, '10': 0},\n",
       "    'avsr': {'-10': 0, '-5': 0, '0': 0, '5': 0, '10': 0}},\n",
       "   'fr': {'asr': {'-10': 0, '-5': 0, '0': 0, '5': 0, '10': 0},\n",
       "    'avsr': {'-10': 0, '-5': 0, '0': 0, '5': 0, '10': 0}},\n",
       "   'it': {'asr': {'-10': 0, '-5': 0, '0': 0, '5': 0, '10': 0},\n",
       "    'avsr': {'-10': 0, '-5': 0, '0': 0, '5': 0, '10': 0}},\n",
       "   'pt': {'asr': {'-10': 0, '-5': 0, '0': 0, '5': 0, '10': 0},\n",
       "    'avsr': {'-10': 0, '-5': 0, '0': 0, '5': 0, '10': 0}}}}}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# root = '../decode/models/checkpoint/'\n",
    "# checkpoint = 'whisper-flamingo_medium_multi-all_normalized_b0.6'\n",
    "\n",
    "root = '../decode/models/'\n",
    "# checkpoint= 'whisper_multi-all_medium.pt'\n",
    "# checkpoint = 'whisper_multi-all_small.pt'\n",
    "# checkpoint = 'whisper-flamingo_multi-all_small.pt'\n",
    "checkpoint = 'whisper-flamingo_multi-all_medium.pt'\n",
    "\n",
    "# ASR zero-shot\n",
    "# checkpoint = 'medium'\n",
    "# checkpoint = 'small'\n",
    "# root = '../decode/'\n",
    "\n",
    "normalizer = 'fairseq'\n",
    "langs = ['en', 'es', 'fr', 'it', 'pt',] \n",
    "noises = [-10, -5, 0, 5, 10] # clean, 0\n",
    "noise_fns = ['lrs3', 'muavic', 'babble', 'speech','music', 'noise', ]\n",
    "modalities = ['asr', 'avsr']\n",
    "beams = [5]\n",
    "visible = 0 # full set\n",
    "\n",
    "\n",
    "results = {noise_fn: {beam: {lang: {modality: {str(noise): 0 for noise in noises} for modality in modalities} for lang in langs} for beam in beams} for noise_fn in noise_fns}\n",
    "for noise_fn in noise_fns:\n",
    "    print(noise_fn)\n",
    "    for beam in beams:\n",
    "        for lang in langs:\n",
    "            for noise in noises:\n",
    "                for modality in modalities:\n",
    "                    try:\n",
    "                        # file = 'wer.368862' if lang == 'en' else 'bleu.368862'\n",
    "                        file = 'wer.368862'\n",
    "                        wer_path = os.path.join(root, checkpoint, lang, 'test', modality, 'snr-{}'.format(noise), 'visible-{}'.format(visible), 'beam-{}'.format(beam), noise_fn, file)\n",
    "                        # print(wer_path)\n",
    "                        with open(wer_path) as f:                    \n",
    "                            first_line = f.readline().strip('\\n')\n",
    "                            # prefix = 5 if lang == 'en' else 6\n",
    "                            prefix = 5\n",
    "                            results[noise_fn][beam][lang][modality][str(noise)] = round(float(first_line[prefix:]), 1)\n",
    "                            # results[noise_fn][beam][lang][modality][str(noise)] = round(compute_wer(wer_path, normalizer, lang), 1)\n",
    "                    except:\n",
    "                        continue\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "whisper-flamingo_multi-all_medium.pt\n",
      "-10  -5  0   5   10  -10  -5  0   5   10  -10  -5  0   5   10  -10  -5  0   5   10  -10  -5  0   5   10  -10  -5  0   5   10  \n",
      "en\n",
      "40.0 25.7 7.5 3.8 3.4 40.9 32.2 8.7 4.0 3.6 39.7 22.1 6.1 3.7 3.6 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 \n",
      "es\n",
      "91.2 70.3 28.0 13.9 9.9 97.6 77.8 32.2 14.4 10.1 91.0 0 26.2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 \n",
      "fr\n",
      "98.1 63.3 27.5 16.0 12.7 107.2 75.1 30.7 17.1 12.7 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 \n",
      "it\n",
      "92.7 73.3 35.2 18.0 12.6 0 0 37.0 18.3 12.6 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 \n",
      "pt\n",
      "94.5 74.3 36.0 20.0 13.7 100.4 79.7 38.6 20.1 14.1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 \n"
     ]
    }
   ],
   "source": [
    "# languages = list(results[noise_fn][beam].keys())\n",
    "\n",
    "print(checkpoint)\n",
    "# modality = 'asr'\n",
    "modality = 'avsr'\n",
    "beam = 5\n",
    "print('-10  -5  0   5   10  ' * 6)\n",
    "for lang in langs:\n",
    "    print(lang)\n",
    "    scores = [results[noise_fn][beam][lang][modality][str(noise)] for noise_fn in noise_fns for noise in noises ]\n",
    "    for val in scores:\n",
    "        print(str(val) + ' ', end='')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test text normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/users/roudi/vtenvs/anaconda3/envs/muavic/lib/python3.8/site-packages/torch/cuda/__init__.py:546: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import editdistance\n",
    "from whisper.normalizers import EnglishTextNormalizer, BasicTextNormalizer\n",
    "from fairseq.scoring.wer import WerScorer, WerScorerConfig\n",
    "\n",
    "def compute_wer(wer_path, normalizer, lang):\n",
    "    scorer = WerScorer(\n",
    "    WerScorerConfig(\n",
    "        wer_tokenizer=\"13a\",\n",
    "        wer_remove_punct=True,\n",
    "        wer_char_level=False,\n",
    "        wer_lowercase=True\n",
    "        )\n",
    "    )\n",
    "    if lang == 'en':\n",
    "        std = EnglishTextNormalizer()\n",
    "    else:\n",
    "        std = BasicTextNormalizer()\n",
    "    w_err, w_len = 0, 0\n",
    "    with open(wer_path.replace('wer.368862', 'wer.json'), 'r') as fp:\n",
    "        data = json.load(fp)\n",
    "        hypo = data['pred']\n",
    "        refs = data['refs']\n",
    "        for h, r in zip(hypo, refs):\n",
    "            if normalizer == 'whisper':\n",
    "                w_err += editdistance.eval(std(r).split(), std(h).split())\n",
    "                w_len += len(r.split())\n",
    "            elif normalizer == 'none':\n",
    "                w_err += editdistance.eval(r.split(), h.split())\n",
    "                w_len += len(r.split())\n",
    "            else: \n",
    "                scorer.add_string(ref=r, pred=h)\n",
    "                wer = scorer.score()\n",
    "        if normalizer == 'whisper' or normalizer == 'none':\n",
    "            wer = 100. * w_err/w_len\n",
    "    return wer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Languages en ar de el es fr it pt ru \n",
      "whisper_multi-all_small.pt\n",
      "Beam size: 5\n",
      "Audio-Clean 3.9 73.4 26.4 18.5 9.5 13.8 12.8 12.8 21.2 \n",
      "Audio-Visual-Clean 0 0 0 0 0 0 0 0 0 \n",
      "Audio-Babble-LRS3 16.0 99.5 59.9 56.7 41.7 35.8 50.6 50.2 46.7 \n",
      "Audio-Visual-Babble-LRS3 0 0 0 0 0 0 0 0 0 \n",
      "Avg clean non En: 23.6\n",
      "Avg clean non En: 0.0\n",
      "Avg noisy non En: 55.1\n",
      "Avg noisy non En: 0.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# root = '../decode/models/checkpoint/'\n",
    "# checkpoint = 'whisper-flamingo_multi-all_small.pt'\n",
    "root = '../decode/models/'\n",
    "checkpoint='whisper_multi-all_small.pt'\n",
    "\n",
    "# ASR zero-shot\n",
    "# root = '../decode/'\n",
    "# checkpoint = 'large-v2'\n",
    "# checkpoint = 'medium'\n",
    "# checkpoint = 'small'\n",
    "\n",
    "# fixed\n",
    "langs = ['en', 'ar', 'de', 'el', 'es', 'fr', 'it', 'pt', 'ru'] \n",
    "# langs = ['en', 'es', 'fr', 'it', 'pt',] \n",
    "# langs = ['en', 'ar', 'de', 'el', 'ru'] \n",
    "\n",
    "noises = [1000, 0] # clean, 0\n",
    "modalities = ['asr', 'avsr']\n",
    "beams = [5]\n",
    "visible = 0 # full eval set\n",
    "noise_fn = 'lrs3'\n",
    "# normalizer = 'whisper'\n",
    "normalizer = 'fairseq'\n",
    "\n",
    "results = {beam: {lang: {modality: {str(noise): 0 for noise in noises} for modality in modalities} for lang in langs} for beam in beams}\n",
    "for beam in beams:\n",
    "    for lang in langs:\n",
    "        for noise in noises:\n",
    "            for modality in modalities:\n",
    "                try:\n",
    "                    file = 'wer.368862'\n",
    "                    # NOTE: new decoding includes noise file name\n",
    "                    wer_path = os.path.join(root, checkpoint, lang, 'test', modality, 'snr-{}'.format(noise), 'visible-{}'.format(visible), 'beam-{}'.format(beam), noise_fn, file)\n",
    "                    # NOTE: old decoding doesn't include noise file name\n",
    "                    # wer_path = os.path.join(root, checkpoint, lang, 'test', modality, 'snr-{}'.format(noise), 'visible-{}'.format(visible), 'beam-{}'.format(beam), file)\n",
    "                    with open(wer_path) as f:                    \n",
    "                        first_line = f.readline().strip('\\n')\n",
    "                        prefix = 5\n",
    "                        results[beam][lang][modality][str(noise)] = round(compute_wer(wer_path, normalizer, lang), 1)\n",
    "                except:\n",
    "                    continue\n",
    "    \n",
    "print('Languages ', end='')\n",
    "for lang in langs:\n",
    "    print(lang + ' ', end='')\n",
    "print()\n",
    "print(checkpoint)\n",
    "# print(noises)\n",
    "ckpt_root = '/usr/users/roudi/whisper-flamingo/models/checkpoint'\n",
    "try:\n",
    "    print(os.readlink(os.path.join(ckpt_root, checkpoint)).split('/')[-1])\n",
    "except:\n",
    "    pass\n",
    "for beam in beams:\n",
    "    print_results(results, beam)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "muavic",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
